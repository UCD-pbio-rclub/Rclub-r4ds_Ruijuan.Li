---
title: "R_club"
author: "Ruijuan Li"
date: "4/12/2017"
output: html_document
---

# 04-12-2017 
```{r}
# expand.grid(1:3, letters) 
```

# 04-26-2017 
```{r include=FALSE}
colorFunc <- "heat.colors"
colorFunc <- "terrain.colors"

```

## `r colorFunc`
```{r fig.cap="The Mounga Whau volcano.", echo=FALSE}
image(volcano, col = get(colorFunc)(200))
```

# book reading & practice 
```{r}
# install.packages("tidyverse")
library(tidyverse)
ggplot2::ggplot()

# data.frame VS matrix VS data.matrix VS as.data.frame 

mpg
class(mpg)
```

```{r}
# plot 
ggplot(data = mpg) + geom_point(mapping = aes(x=displ, y= hwy))
# mapping? 

# Each geom function in ggplot2 takes a mapping argument. This defines how variables in your dataset are mapped to visual properties.The mapping argument is always paired with aes(), and the x and y arguments of aes() specify which variables to map to the x and y axes.  
```

```{r}
# template 
# ggplot(data = <DATA>) + 
#   <GEOM_FUNCTION>(mapping = aes(<MAPPINGS>))  
```

```{r}
ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy, color = class)) 

ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy, size = class))

# mapping an unordered variable (class) to an ordered aesthetic (size) is not a good idea. 

# Left
ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy, alpha = class))

# Right
ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy, shape = class))

# ggplot2 will only use six shapes at a time. By default, additional groups will go unplotted when you use the shape aesthetic. 

# set the aesthetic properties of your geom manually. For example, we can make all of the points in our plot blue

ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy), color = "blue")

ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy), color = "red", size = 3, shape = 0, fill="red")
# To set an aesthetic manually, set the aesthetic by name as an argument of your geom function; i.e. it goes outside of aes(). 

# how to fill? 

# To facet your plot by a single variable, use facet_wrap(); The variable that you pass to facet_wrap() should be discrete. 

ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy)) + 
  facet_wrap(~ class, nrow = 2)

# To facet your plot on the combination of two variables, add facet_grid() to your plot call. 

ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy)) + 
  facet_grid(drv ~ cyl)

ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy)) + 
  facet_grid( ~ cyl)

ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy)) + 
  facet_grid(drv ~ .)

```

# 05-02-2017
```{r}
library(ggplot2)
# left
ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy))

# right
ggplot(data = mpg) + 
  geom_smooth(mapping = aes(x = displ, y = hwy))

ggplot(data = mpg) + 
  geom_smooth(mapping = aes(x = displ, y = hwy, linetype = drv))

mpg$drv

# compared to linetype, better to use group because it doens't add extra legend 
ggplot(data = mpg) +
  geom_smooth(mapping = aes(x = displ, y = hwy))
              
ggplot(data = mpg) +
  geom_smooth(mapping = aes(x = displ, y = hwy, group = drv))
    
ggplot(data = mpg) +
  geom_smooth(
    mapping = aes(x = displ, y = hwy, group = drv)
  )

# multiple geom 
ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy)) +
  geom_smooth(mapping = aes(x = displ, y = hwy))

# global mapping 
ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + 
  geom_point() + 
  geom_smooth()

# overlay with color 
ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + 
  geom_point(mapping = aes(color = class)) + 
  geom_smooth()

# the use of filter 
library(dplyr)
ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + 
  geom_point(mapping = aes(color = class)) +  
  geom_smooth(data = filter(mpg, class == "subcompact"), se = FALSE)

# statistical transformation
ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut))

# stat_count & geom_bar are the same thing 
ggplot(data = diamonds) + 
  stat_count(mapping = aes(x = cut))

# use identity as stats 
library(tibble)
demo <- tribble(
  ~a,      ~b,
  "bar_1", 20,
  "bar_2", 30,
  "bar_3", 40
)
ggplot(data = demo) +
  geom_bar(mapping = aes(x = a, y = b), stat = "identity")

# use proportion as stats
ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut, y = ..prop.., group = 1)) 

# stat_summary 
ggplot(data = diamonds) + 
  stat_summary(
    mapping = aes(x = cut, y = depth),
    fun.ymin = min,
    fun.ymax = max,
    fun.y = median
  )

# color vs fill 
ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut, colour = cut))
ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut, fill = cut))

# Each colored rectangle represents a combination of cut and clarity
ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut, fill = clarity))

# position: identity OR dodge OR fill OR jitter OR stack 
# position = "identity" will place each object exactly where it falls in the context of the graph. This is not very useful for bars, because it overlaps them.

ggplot(data = diamonds, mapping = aes(x = cut, fill = clarity)) + 
  geom_bar(alpha = 1/5, position = "identity")
ggplot(data = diamonds, mapping = aes(x = cut, colour = clarity)) + 
  geom_bar(fill = NA, position = "identity")

# position = "fill" works like stacking, but makes each set of stacked bars the same height. This makes it easier to compare proportions across groups.

ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut, fill = clarity), position = "fill")

# position = "dodge" places overlapping objects directly beside one another. This makes it easier to compare individual values 
ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut, fill = clarity), position = "dodge")

# overplotting problem for scatterplot 
ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy), position = "jitter")

#### coordinate system 
ggplot(data = mpg, mapping = aes(x = class, y = hwy)) + 
  geom_boxplot()
ggplot(data = mpg, mapping = aes(x = class, y = hwy)) + 
  geom_boxplot() +
  coord_flip()

# install.packages("maps")
library("maps")
nz <- map_data("nz")

ggplot(nz, aes(long, lat, group = group)) +
  geom_polygon(fill = "white", colour = "black")

ggplot(nz, aes(long, lat, group = group)) +
  geom_polygon(fill = "white", colour = "black") +
  coord_quickmap()

bar <- ggplot(data = diamonds) + 
  geom_bar(
    mapping = aes(x = cut, fill = cut), 
    show.legend = FALSE,
    width = 1
  ) + 
  theme(aspect.ratio = 1) +
  labs(x = NULL, y = NULL)

bar
bar + coord_flip()
bar + coord_polar() 

# calculate proportion within each group 
ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut, fill = clarity, y = ..prop..)) 

ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut, fill = clarity))

ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut, y = ..prop.., group = 1))

ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut, fill = clarity), position = "fill")

p <- ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut, y = ..prop.., fill = color))  

grid_arrange
install.packages("gridExtra")
library("gridExtra")   
```

# 05-09-2017 
```{r}
# install.packages("nycflights13")
library(nycflights13)
library(tidyverse)

flights # Tibbles are data frames, but slightly tweaked to work better in the tidyverse.  

# Filter rows with filter() 
filter(flights, month == 1, day == 1)
jan1 <- filter(flights, month == 1, day == 1)
(dec25 <- filter(flights, month == 12, day == 25))

sqrt(2) ^ 2 == 2
1/49 * 49 == 1

near(sqrt(2) ^ 2,  2)
near(1 / 49 * 49, 1)

tmp <- filter(flights, month == 11 | month == 12)
nov_dec <- filter(flights, month %in% c(11, 12))
identical(tmp, nov_dec)

filter(flights, !(arr_delay > 120 | dep_delay > 120))
filter(flights, arr_delay <= 120, dep_delay <= 120)

# As well as & and |, R also has && and ||. Don’t use them here!  
df <- tibble(x = c(1, NA, 3))
df
filter(df, x > 1)
filter(df, is.na(x) | x > 1)

# Arrange rows with arrange()
arrange(flights, year, month, day)
arrange(flights, desc(arr_delay))

### Select columns with select()
select(flights, year, month, day)
select(flights, year:day)
select(flights, -(year:day)) # deselect certain colnames 
colnames(select(flights, matches("(.)\\1")))  ### repeated character... 
?select
rename(flights, tail_num = tailnum)$tail_num # rename certain colnames 
dim(select(flights, time_hour, air_time, everything())) # move time_hour & air_time to the beginning of the df
dim(flights)

# 5.5 Add new variables with mutate() # add new columns which are functions of the existing columns 
flights_sml <- select(flights, 
  year:day, 
  ends_with("delay"), 
  distance, 
  air_time
)

dim(flights_sml)

tmp <- mutate(flights_sml,
  gain = arr_delay - dep_delay,
  speed = distance / air_time * 60
)

dim(tmp)

tmp2 <- mutate(flights_sml,
  gain = arr_delay - dep_delay,
  hours = air_time / 60,
  gain_per_hour = gain / hours
)

dim(tmp2)

transmute(flights,
  gain = arr_delay - dep_delay,
  hours = air_time / 60,
  gain_per_hour = gain / hours
) # only keep the new variables 

colnames(flights)

transmute(flights,
  dep_time,
  hour = dep_time %/% 100,
  minute = dep_time %% 100
)
flights$dep_time

?lead
lead(1:10, 1)
lead(1:10, 2)
lag(1:10, 1)

x <- runif(5)
x
cbind(ahead = lead(x), x, behind = lag(x))

df <- data.frame(year = 2000:2005, value = (0:5) ^ 2)
df
scrambled <- df[sample(nrow(df)), ]
scrambled
wrong <- mutate(scrambled, prev = lag(value))
arrange(wrong, year)

right <- mutate(scrambled, prev = lag(value, order_by = year))
arrange(right, year)

x <- c(1:10)
x
cumsum(x)
cummean(x)

y <- c(1, 2, 2, NA, 3, 4)
min_rank(y) 
min_rank(desc(y))
row_number(y)
dense_rank(y)
percent_rank(y)
cume_dist(y)

```

# 05-16-2017 
```{r}
library(nycflights13)
library(tidyverse)

# introduce group_by & summarise 
summarise(flights, delay = mean(dep_delay, na.rm = TRUE))
dim(flights) # 336776     19
by_day <- group_by(flights, year, month, day)
dim(by_day) # 336776     19 
summarise(by_day, delay = mean(dep_delay, na.rm = TRUE))

# pipe 
# Combining multiple operations with the pipe 
by_dest <- group_by(flights, dest)
delay <- summarise(by_dest,
  count = n(), # what is this??? 
  dist = mean(distance, na.rm = TRUE),
  delay = mean(arr_delay, na.rm = TRUE)
)
delay <- filter(delay, count > 20, dest != "HNL")

ggplot(data = delay, mapping = aes(x = dist, y = delay)) +
  geom_point(aes(size = count), alpha = 1/3) +
  geom_smooth(se = FALSE)

ggplot(data = delay, mapping = aes(x = dist, y = delay)) +
  geom_point(aes(size = count), alpha = 1/3) +
  geom_smooth(se = T)

# se specify whether plot confidence interval 
delays <- flights %>% 
  group_by(dest) %>% 
  summarise(
    count = n(),
    dist = mean(distance, na.rm = TRUE),
    delay = mean(arr_delay, na.rm = TRUE)
  ) %>% 
  filter(count > 20, dest != "HNL")

# missing values 
flights %>% 
  group_by(year, month, day) %>% 
  summarise(mean = mean(dep_delay))

tmp1 <- flights %>% 
  group_by(year, month, day) %>% 
  summarise(mean = mean(dep_delay, na.rm = TRUE))

not_cancelled <- flights %>% 
  filter(!is.na(dep_delay), !is.na(arr_delay))

tmp2 <- not_cancelled %>% 
  group_by(year, month, day) %>% 
  summarise(mean = mean(dep_delay))

dim(tmp1)
dim(tmp2)
head(tmp1)
head(tmp2)
identical(tmp1, tmp2)

### rm.na still keep the data as one data? 
### so tmp1 & tmp2 are different... 

# Counts 
delays <- not_cancelled %>% 
  group_by(tailnum) %>% 
  summarise(
    delay = mean(arr_delay)
  )

ggplot(data = delays, mapping = aes(x = delay)) + 
  geom_freqpoly(binwidth = 10)

ggplot(data = delays, mapping = aes(x = delay)) + 
  geom_freqpoly(binwidth = 100)

ggplot(data = delays, mapping = aes(x = delay)) + 
  geom_freqpoly(binwidth = 1)

?geom_freqpoly
 # Visualise the distribution of a single continuous variable by dividing the x axis into bins and counting the number of observations in each bin. Histograms (geom_histogram) display the count with bars; frequency polygons (geom_freqpoly), display the counts with lines. Frequency polygons are more suitable when you want to compare the distribution across a the levels of a categorical variable. 

delays <- not_cancelled %>% 
  group_by(tailnum) %>% 
  summarise(
    delay = mean(arr_delay, na.rm = TRUE), # na.rm TRUE or FALSE has no effect here 
    n = n() # don't know this... 
  )

ggplot(data = delays, mapping = aes(x = n, y = delay)) + 
  geom_point(alpha = 1/10)

delays %>% 
  filter(n > 25) %>% 
  ggplot(mapping = aes(x = n, y = delay)) + 
    geom_point(alpha = 1/10)

# RStudio tip: a useful keyboard shortcut is Cmd/Ctrl + Shift + P. This resends the previously sent chunk from the editor to the console. This is very convenient when you’re (e.g.) exploring the value of n in the example above. You send the whole block once with Cmd/Ctrl + Enter, then you modify the value of n and press Cmd/Ctrl + Shift + P to resend the complete block. ######### what??? don't understand !!!!!!!!!

# install.packages("Lahman")
library("Lahman")

batting <- as_tibble(Lahman::Batting)

batters <- batting %>% 
  group_by(playerID) %>% 
  summarise(
    ba = sum(H, na.rm = TRUE) / sum(AB, na.rm = TRUE),
    ab = sum(AB, na.rm = TRUE)
  )

batters %>% 
  filter(ab > 100) %>% 
  ggplot(mapping = aes(x = ab, y = ba)) +
    geom_point() + 
    geom_smooth(se = FALSE)

batters %>% 
  arrange(desc(ba))

#### Useful summary functions
not_cancelled %>% 
  group_by(year, month, day) %>% 
  summarise(
    avg_delay1 = mean(arr_delay),
    avg_delay2 = mean(arr_delay[arr_delay > 0]) # the average positive delay
  )

not_cancelled %>% 
  group_by(dest) %>% 
  summarise(distance_sd = sd(distance)) %>% 
  arrange(desc(distance_sd))

not_cancelled %>% 
  group_by(year, month, day) %>% 
  summarise(
    first = min(dep_time),
    last = max(dep_time)
  )

not_cancelled %>% 
  group_by(year, month, day) %>% 
  summarise(
    first_dep = first(dep_time), 
    last_dep = last(dep_time)
  )

tmp <- 
not_cancelled %>% 
  group_by(year, month, day) %>% 
  mutate(r = min_rank(desc(dep_time))) %>% 
  filter(r %in% range(r)) # don't understand the last line of code... 

tmp2 <- 
not_cancelled %>% 
  group_by(year, month, day) %>% 
  mutate(r = min_rank(desc(dep_time))) 

?range  
identical(tmp, tmp2)

not_cancelled %>% 
  group_by(dest) %>% 
  summarise(carriers = n_distinct(carrier)) %>% 
  arrange(desc(carriers))

not_cancelled %>% 
  count(dest)

# n() takes no arguments, and returns the size of the current group.

not_cancelled %>% 
  count(tailnum, wt = distance) # the total number of miles a plane flew 

not_cancelled %>% 
  count(tailnum)
```

# 05-23-2017 
```{r}
library(tidyverse)
ggplot(data = diamonds) +
  geom_bar(mapping = aes(x = cut))

diamonds %>% 
  count(cut)

ggplot(data = diamonds) +
  geom_histogram(mapping = aes(x = carat), binwidth = 0.5)

diamonds %>% 
  count(cut_width(carat, 0.5)) # this is very useful, can be used in window size... 

summary(diamonds)

smaller <- diamonds %>% 
  filter(carat < 3)
  
ggplot(data = smaller, mapping = aes(x = carat)) +
  geom_histogram(binwidth = 0.1)

ggplot(data = smaller, mapping = aes(x = carat, colour = cut)) +
  geom_freqpoly(binwidth = 0.1) # this can be useful for my data analysis 

ggplot(data = faithful, mapping = aes(x = eruptions)) + 
  geom_histogram(binwidth = 0.25)

ggplot(diamonds) + 
  geom_histogram(mapping = aes(x = y), binwidth = 0.5)

ggplot(diamonds) + 
  geom_histogram(mapping = aes(x = y), binwidth = 0.5) +
  coord_cartesian(ylim = c(0, 50)) # zoom in to see outliners 

unusual <- diamonds %>% 
  filter(y < 3 | y > 20) %>% 
  select(price, x, y, z) %>%
  arrange(y)
unusual

summary(diamonds)
sample(1:594, 1, replace = F) # pick a question from leetcode... 
 
diamonds2 <- diamonds %>% 
  mutate(y = ifelse(y < 3 | y > 20, NA, y))

ggplot(data = diamonds2, mapping = aes(x = x, y = y)) + 
  geom_point()

nycflights13::flights %>% 
  mutate(
    cancelled = is.na(dep_time),
    sched_hour = sched_dep_time %/% 100,
    sched_min = sched_dep_time %% 100,
    sched_dep_time = sched_hour + sched_min / 60
  ) %>% 
  ggplot(mapping = aes(sched_dep_time)) + 
    geom_freqpoly(mapping = aes(colour = cancelled), binwidth = 1/4)

ggplot(data = diamonds, mapping = aes(x = price, y = ..density..)) + 
  geom_freqpoly(mapping = aes(colour = cut), binwidth = 500) # this can be useful for my data 

ggplot(data = diamonds, mapping = aes(x = cut, y = price)) +
  geom_boxplot() # geom box plot can be useful 

ggplot(data = mpg, mapping = aes(x = class, y = hwy)) +
  geom_boxplot()

ggplot(data = mpg) +
  geom_boxplot(mapping = aes(x = reorder(class, hwy, FUN = median), y = hwy)) # reorder based on median value of 

ggplot(data = mpg) +
  geom_boxplot(mapping = aes(x = reorder(class, hwy, FUN = median), y = hwy)) +
  coord_flip()

diamonds %>% 
  count(color, cut)

diamonds %>% 
  count(color, cut) %>%  
  ggplot(mapping = aes(x = color, y = cut)) +
    geom_tile(mapping = aes(fill = n))

# install.packages("hexbin")
library(hexbin)
ggplot(data = smaller) +
  geom_bin2d(mapping = aes(x = carat, y = price))

ggplot(data = smaller) +
  geom_hex(mapping = aes(x = carat, y = price))

```

05-28-2017
```{r}
# 7.6 Patterns & models 
library(modelr)
library(ggplot2)
library(tidyverse)

mod <- lm(log(price) ~ log(carat), data = diamonds)
mod

diamonds2 <- diamonds %>% 
  add_residuals(mod) %>% 
  mutate(resid = exp(resid))
?add_residuals # add residuals to a data frame 
add_residuals(data = diamonds, model = mod) 
?exp # compute the exponential function 
# The residuals give us a view of the price of the diamond, once the effect of carat has been removed. 

ggplot(data = diamonds2) + 
  geom_point(mapping = aes(x = carat, y = resid))
# when carat is small, residual is high, when carat if high, residual is low. higher precision when carat is high, lower precision when carat is low, this is due to the log transformation.  

# I want to plot how the data fit the model
ggplot(data = diamonds2) + 
  geom_point(mapping = aes(x=log(carat), y=log(price), alpha=0.01)) + 
  geom_abline(intercept = mod$coefficients[[1]], slope = mod$coefficients[[2]], color="red")

ggplot(data = diamonds2) + 
  geom_boxplot(mapping = aes(x = cut, y = resid))

# 7.7 ggplot2 calls 

# 10.2 creating tibbles 
as.tibble(iris)

tibble(
  x = 1:5, 
  y = 1, 
  z = x ^ 2 + y
)

# It’s possible for a tibble to have column names that are not valid R variable names, aka non-syntactic names.  
tb <- tibble(
  `:)` = "smile", 
  ` ` = "space",
  `2000` = "number"
)

tb

# 10.3 tibbles vs. data.frame 
# printing diff 
# Tibbles have a refined print method that shows only the first 10 rows, and all the columns that fit on screen. This makes it much easier to work with large data. In addition to its name, each column reports its type, a nice feature borrowed from str(): 

tibble(
  a = lubridate::now() + runif(1e3) * 86400,
  b = lubridate::today() + runif(1e3) * 30,
  c = 1:1e3,
  d = runif(1e3),
  e = sample(letters, 1e3, replace = TRUE)
)

nycflights13::flights %>% 
  print(n = 10, width = Inf)

# subsetting 
df <- tibble(
  x = runif(5),
  y = rnorm(5)
)

df$x
df[["x"]]
df[[1]]
df[,1]
# tibble doesn't do partial matching, so that means not very useful in real world analysis 

# 10.4 interacting with older code 
```

# 06-07-2017 
```{r}
# data import 
library(tidyverse)
?read_fwf
fwf_sample <- readr_example("fwf-sample.txt")
fwf_sample
cat(read_lines(fwf_sample))
?read_log

read_csv("a,b,c
1,2,3
4,5,6")

read_csv("The first line of metadata
  The second line of metadata
  x,y,z
  1,2,3", skip = 2) # skip might be useful in my analysis 

read_csv("The first line of metadata
  The second line of metadata
  x,y,z
  1,2,3")

read_csv("# A comment I want to skip
  x,y,z
  1,2,3", comment = "#")

read_csv("1,2,3\n4,5,6", col_names = FALSE)

read_csv("a,b,c\n1,2,.", na = ".")

### parse vector 
# number 
parse_double("1.23")
parse_double("1,23", locale = locale(decimal_mark = ","))

parse_number("$100")
parse_number("20%")
parse_number("It cost $123.45") # these can be very useful in data parsing... 

# Used in America
parse_number("$123,456,789")
#> [1] 1.23e+08

# Used in many parts of Europe
parse_number("123.456.789", locale = locale(grouping_mark = "."))
#> [1] 1.23e+08

# Used in Switzerland
parse_number("123'456'789", locale = locale(grouping_mark = "'"))
#> [1] 1.23e+08 
# the above can be useful for collaboration... 

# string 
x1 <- "El Ni\xf1o was particularly bad this year"
x2 <- "\x82\xb1\x82\xf1\x82\xc9\x82\xbf\x82\xcd"

x1
#> [1] "El Ni\xf1o was particularly bad this year"
x2
#> [1] "\x82\xb1\x82\xf1\x82ɂ\xbf\x82\xcd"

parse_character(x1, locale = locale(encoding = "Latin1"))
#> [1] "El Niño was particularly bad this year"
parse_character(x2, locale = locale(encoding = "Shift-JIS"))
#> [1] "こんにちは"

# use guess_encoding 
guess_encoding(charToRaw(x1))
#> # A tibble: 2 × 2
#>     encoding confidence
#>        <chr>      <dbl>
#> 1 ISO-8859-1       0.46
#> 2 ISO-8859-9       0.23
guess_encoding(charToRaw(x2))
#> # A tibble: 1 × 2
#>   encoding confidence
#>      <chr>      <dbl>
#> 1   KOI8-R       0.42

#### Factors 
fruit <- c("apple", "banana")
parse_factor(c("apple", "banana", "bananana"), levels = fruit)

fruit <- c("apple", "banana", "bananana")
parse_factor(c("apple", "banana", "bananana"), levels = fruit)

# Dates, date-times, and times 
parse_datetime("2010-10-01T2010")
#> [1] "2010-10-01 20:10:00 UTC"
# If time is omitted, it will be set to midnight
parse_datetime("20101010")
#> [1] "2010-10-10 UTC"

library(hms)
parse_time("01:10 am")
#> 01:10:00
parse_time("20:10:01")
#> 20:10:01

parse_date("01/02/15", "%m/%d/%y")
#> [1] "2015-01-02"
parse_date("01/02/15", "%d/%m/%y")
#> [1] "2015-02-01"
parse_date("01/02/15", "%y/%m/%d")
#> [1] "2001-02-15"

# Other Types of Data
# many useful packages to extract information from different type of data  
```

# 06-21-2017 
```{r}
# missing data explicit or implicit 
library(tidyverse)
stocks <- tibble(
  year   = c(2015, 2015, 2015, 2015, 2016, 2016, 2016),
  qtr    = c(   1,    2,    3,    4,    2,    3,    4),
  return = c(1.88, 0.59, 0.35,   NA, 0.92, 0.17, 2.66)
)

stocks %>% 
  spread(key = year, value = return) %>% 
  gather(key = year, value = rerun, `2015`, `2016`, na.rm=T)

stocks %>% 
  complete(year, qtr) 
# complete() takes a set of columns, and finds all unique combinations. It then ensures the original dataset contains all those values, filling in explicit NAs where necessary. 

treatment <- tribble(
  ~ person,           ~ treatment, ~response,
  "Derrick Whitmore", 1,           7,
  NA,                 2,           10,
  NA,                 3,           9,
  "Katherine Burke",  1,           4
)

treatment %>% 
  fill(person) # this can be quite useful !!! 

# case study 
who

# 1) collapse values into variables 
who1 <- who %>% 
  gather(new_sp_m014:newrel_f65, key = "key", value = "cases", na.rm = TRUE)
who1

# 2) explore the data & understand the data structure
who1 %>% 
  count(key)

who1 %>% 
  count(key, wt = cases)

# 3) make consistent value names 
who2 <- who1 %>% 
  mutate(key = stringr::str_replace(key, "newrel", "new_rel"))
who2

# 4) seperate key to different variables 
who3 <- who2 %>% 
  separate(key, c("new", "type", "sexage"), sep = "_")
who3 

# 5) explore & drop repeated & constant variables 
who3 %>% 
  count(new) 

who4 <- who3 %>% 
  select(-new, -iso2, -iso3)

# 6) seprate sex & age into different variables 
who5 <- who4 %>% 
  separate(sexage, c("sex", "age"), sep = 1)
who5

# tidy data!!! 

# piece the above tidying code together in a pipe 
who %>%
  gather(code, value, new_sp_m014:newrel_f65, na.rm = TRUE) %>% 
  mutate(code = stringr::str_replace(code, "newrel", "new_rel")) %>%
  separate(code, c("new", "var", "sexage")) %>% 
  select(-new, -iso2, -iso3) %>% 
  separate(sexage, c("sex", "age"), sep = 1) 

# mutating joins 
# filtering joins
# set operations 

library(tidyverse)
library(nycflights13)

# nycflights13 contains four tibbles that are related to the flights table
airlines
airports
planes
weather
```

# 06-28-2017 
```{r}
library(tidyverse)
library(nycflights13)

# A primary key uniquely identifies an observation in its own table. 
# Once you’ve identified the primary keys in your tables, it’s good practice to verify that they do indeed uniquely identify each observation. One way to do that is to count() the primary keys and look for entries where n is greater than one: 
planes %>% 
  count(tailnum) %>% # count is very important 
  filter(n > 1)

weather %>% 
  count(year, month, day, hour, origin) %>% 
  filter(n > 1)

flights %>% 
  count(year, month, day, flight) %>% 
  filter(n > 1)

flights %>% 
  count(year, month, day, tailnum) %>% 
  filter(n > 1)

#  If a table lacks a primary key, it’s sometimes useful to add one with mutate() and row_number(). That makes it easier to match observations if you’ve done some filtering and want to check back in with the original data. This is called a surrogate key. 

# Mutating joins
flights2 <- flights %>% 
  select(year:day, hour, origin, dest, tailnum, carrier)
colnames(flights2)
colnames(airlines)

flights2 %>%
  select(-origin, -dest) %>% 
  left_join(airlines, by = "carrier") # left join 

?left_join

flights2 %>%
  select(-origin, -dest) %>% 
  mutate(name = airlines$name[match(carrier, airlines$carrier)]) 

# 13.4.1 Understanding joins
x <- tribble(
  ~key, ~val_x,
     1, "x1",
     2, "x2",
     3, "x3"
)
y <- tribble(
  ~key, ~val_y,
     1, "y1",
     2, "y2",
     4, "y3"
)

x
y

# 13.4.2 Inner join
x %>% 
  inner_join(y, by = "key")

# 13.4.3 Outer joins

# 13.4.4 Duplicate keys
x <- tribble(
  ~key, ~val_x,
     1, "x1",
     2, "x2",
     2, "x3",
     1, "x4"
)
y <- tribble(
  ~key, ~val_y,
     1, "y1",
     2, "y2"
)
left_join(x, y, by = "key")

x <- tribble(
  ~key, ~val_x,
     1, "x1",
     2, "x2",
     2, "x3",
     3, "x4"
)
y <- tribble(
  ~key, ~val_y,
     1, "y1",
     2, "y2",
     2, "y3",
     3, "y4"
)
left_join(x, y, by = "key")

# 13.4.5 Defining the key columns
flights2 %>% 
  left_join(weather)

colnames(flights2)
colnames(weather)

intersect(colnames(flights2), colnames(weather))

flights2 %>% 
  left_join(planes, by = "tailnum")

colnames(flights2)
colnames(airports)

flights2 %>% 
  left_join(airports, c("dest" = "faa")) %>%
  colnames()

flights2 %>% 
  left_join(airports, c("origin" = "faa"))



```

# 07-12-2017 
```{r}
library(tidyverse)
library(stringr)

string1 <- "This is a string"
string2 <- 'If I want to include a "quote" inside a string, I use single quotes'
string2
writeLines(string2)

double_quote <- "\"" # or '"' ???
single_quote <- '\'' # or "'" ???
writeLines(double_quote)
writeLines(single_quote)

x <- c("\"", "\\")
x
writeLines(x)

x <- "\u00b5"
x

?"'" 
str_length(c("a", "R for data science", NA)) # length of string ... 

str_c("x", "y") # combine strings
str_c("x", "y", "z") # combine strings 

str_c("x", "y", sep = ", ") # use sep to specify how they are seperated... 

x <- c("abc", NA) # missing values are contagious. 
x
str_c("|-", x, "-|")
str_c("|-", str_replace_na(x), "-|")

str_c("prefix-", c("a", "b", "c"), "-suffix")

name <- "Hadley"
time_of_day <- "morning"
birthday <- FALSE

str_c(
  "Good ", time_of_day, " ", name,
  if (birthday) " and HAPPY BIRTHDAY",
  "."
)

# To collapse a vector of strings into a single string, use collapse:
c("x", "y", "z")
str_c(c("x", "y", "z"), collapse = ", ")

x <- c("Apple", "Banana", "Pear")
str_sub(x, 1, 3)
str_sub(x, -3, -1)

# Note that str_sub() won’t fail if the string is too short: it will just return as much as possible:
str_sub("a", 1, 5)

# Turkish has two i's: with and without a dot, and it
# has a different rule for capitalising them:
str_to_upper(c("i", "ı"))
#> [1] "I" "I"
str_to_upper(c("i", "ı"), locale = "tr")
#> [1] "İ" "I"
# useful when working with international collaborators 

x <- c("apple", "eggplant", "banana")
x

str_sort(x, locale = "en")  # English
#> [1] "apple"    "banana"   "eggplant"

str_sort(x, locale = "haw") # Hawaiian
#> [1] "apple"    "eggplant" "banana"
```

# 07-19-2017 
```{r}
library(tidyverse)
library(stringr)
# 14.3 Matching patterns with regular expressions
x <- c("apple", "banana", "pear")
str_view(x, "an")

str_view(x, ".a.") # . matches any character except for new line 
# to create the regular expression \. we need the string "\\." 

# To create the regular expression, we need \\
dot <- "\\."

# But the expression itself only contains one:
writeLines(dot)
#> \.

# And this tells R to look for an explicit .
str_view(c("abc", "a.c", "bef"), "a\\.c")

# to match a literal \ you need to write "\\\\" — you need four backslashes to match one 
x <- "a\\b"
writeLines(x)
#> a\b

str_view(x, "\\\\") 

# 14.3.2 Anchors
x <- c("apple", "banana", "pear")
str_view(x, "^a")

str_view(x, "a$")

x <- c("apple pie", "apple", "apple cake")
str_view(x, "apple")
str_view(x, "^apple$")

# 14.3.3 Character classes and alternatives
# \d: matches any digit.
# \s: matches any whitespace (e.g. space, tab, newline).
# [abc]: matches a, b, or c.
# [^abc]: matches anything except a, b, or c.
str_view(c("grey", "gray"), "gr(e|a)y")

# 14.3.4 Repetition
# ?: 0 or 1
# +: 1 or more
# *: 0 or more

x <- "1888 is the longest year in Roman numerals: MDCCCLXXXVIII"
str_view(x, "CC?")

str_view(x, "CC+")
str_view(x, 'C[LX]+')

# you can also specify the number of matches precisely:

# {n}: exactly n
# {n,}: n or more
# {,m}: at most m
# {n,m}: between n and m

str_view(x, "C{2}")
str_view(x, "C{2,}")
str_view(x, "C{2,3}")
str_view(x, 'C{2,3}?')


######### 
# 14.4.1 Detect matches
library("tidyverse")
library("stringr")

x <- c("apple", "banana", "pear")
str_detect(x, "e")

# How many common words start with t?
words
sum(str_detect(words, "^t"))
#> [1] 65
# What proportion of common words end with a vowel?
mean(str_detect(words, "[aeiou]$"))
sum(str_detect(words, "[aeiou]$")) 
?mean
#> [1] 0.277

# Find all words containing at least one vowel, and negate
no_vowels_1 <- !str_detect(words, "[aeiou]")
# Find all words consisting only of consonants (non-vowels)
no_vowels_2 <- str_detect(words, "^[^aeiou]+$")
identical(no_vowels_1, no_vowels_2)
#> [1] TRUE 

words[str_detect(words, "x$")]
#> [1] "box" "sex" "six" "tax"
str_subset(words, "x$")
#> [1] "box" "sex" "six" "tax"

df <- tibble(
  word = words, 
  i = seq_along(word)
)
head(df)

df %>% 
  filter(str_detect(words, "x$")) # this can be very useful in real data analysis 
x <- c("apple", "banana", "pear")
str_count(x, "a")
#> [1] 1 3 1

# On average, how many vowels per word?
mean(str_count(words, "[aeiou]"))
#> [1] 1.99

sum(str_count(words, "[aeiou]")) / length(words)

# It’s natural to use str_count() with mutate():

df %>% 
  mutate(
    vowels = str_count(word, "[aeiou]"),
    consonants = str_count(word, "[^aeiou]")
  )

str_count("abababa", "aba")
#> [1] 2
str_view_all("abababa", "aba")

length(sentences)
sentences

colours <- c("red", "orange", "yellow", "green", "blue", "purple")
colour_match <- str_c(colours, collapse = "|")
colour_match

has_colour <- str_subset(sentences, colour_match)
has_colour
matches <- str_extract(has_colour, colour_match)
head(matches)

more <- sentences[str_count(sentences, colour_match) > 1]
more
str_view_all(more, colour_match) 

str_extract(more, colour_match) # why no red? because it appears multiple times? 
colour_match
str_extract_all(more, colour_match)
?str_extract
str_extract_all(more, colour_match, simplify = TRUE)
x <- c("a", "a b", "a b c")
str_extract_all(x, "[a-z]", simplify = TRUE) 

# 14.4.4 Grouped matches
noun <- "(a|the) ([^ ]+)"

has_noun <- sentences %>%
  str_subset(noun) %>%
  head(10)

has_noun
str_subset(sentences, noun) %>% head(10) %>% str_extract(noun)

has_noun %>% 
  str_extract(noun)

has_noun %>%
  str_match(noun)

tibble(sentence = sentences) %>%
  tidyr::extract(
    sentence, c("article", "noun"), "(a|the) ([^ ]+)",
    remove = FALSE
  )

# 14.4.5 Replacing matches
x <- c("apple", "pear", "banana")
str_replace(x, "[aeiou]", "-")

str_replace_all(x, "[aeiou]", "-")

x <- c("1 house", "2 cars", "3 people")
str_replace_all(x, c("1" = "one", "2" = "two", "3" = "three"))

sentences %>% 
  str_replace("([^ ]+) ([^ ]+) ([^ ]+)", "\\1 \\3 \\2") %>% 
  head(5)

head(sentences, 5)

sentences %>%
  head(5) %>% 
  str_split(" ")

"a|b|c|d" %>% 
  str_split("\\|") %>% 
  .[[1]]

"a|b|c|d" %>% 
  str_split("\\|")

sentences %>%
  head(5) %>% 
  str_split(" ", simplify = TRUE)

str_view("bananana", "(..)\\1{1}") # don't understand this... two letters repeat twice 
str_view("pepper", "(.)(.)\\1")  
```

# 13.5 Filtering joins
```{r}
top_dest <- flights %>%
  count(dest, sort = TRUE) %>%
  head(10)

top_dest

flights %>% 
  filter(dest %in% top_dest$dest)

flights %>% 
  semi_join(top_dest) %>%
  select(dest) %>%
  unique()

flights %>%
  anti_join(planes, by = "tailnum") %>%
  count(tailnum, sort = TRUE)
```

# 07-26-2017 
```{r}
library(tidyverse)
library(forcats)

# 15.2 Creating factors
x1 <- c("Dec", "Apr", "Jan", "Mar")
x1

month_levels <- c(
  "Jan", "Feb", "Mar", "Apr", "May", "Jun", 
  "Jul", "Aug", "Sep", "Oct", "Nov", "Dec"
)

y1 <- factor(x1, levels = month_levels)
y1

sort(y1)

x2 <- c("Dec", "Apr", "Jam", "Mar")
y2 <- factor(x2, levels = month_levels)
y2

y2 <- parse_factor(x2, levels = month_levels)

# 15.3 General Social Survey 
gss_cat

gss_cat %>%
  count(race)

ggplot(gss_cat, aes(race)) +
  geom_bar()

ggplot(gss_cat, aes(race)) +
  geom_bar() +
  scale_x_discrete(drop = FALSE)

relig_summary <- gss_cat %>%
  group_by(relig) %>%
  summarise(
    age = mean(age, na.rm = TRUE),
    tvhours = mean(tvhours, na.rm = TRUE),
    n = n()
  )

ggplot(relig_summary, aes(tvhours, relig)) + geom_point()

ggplot(relig_summary, aes(tvhours, fct_reorder(relig, tvhours))) +
  geom_point() # this can be useful when plotting my own data 

?fct_reorder

relig_summary %>%
  mutate(relig = fct_reorder(relig, tvhours)) %>%
  ggplot(aes(tvhours, relig)) +
    geom_point()

relig_summary %>%
  mutate(relig = fct_reorder(relig, tvhours))

rincome_summary <- gss_cat %>%
  group_by(rincome) %>%
  summarise(
    age = mean(age, na.rm = TRUE),
    tvhours = mean(tvhours, na.rm = TRUE),
    n = n()
  )

ggplot(rincome_summary, aes(age, fct_reorder(rincome, age))) + geom_point() 
ggplot(rincome_summary, aes(age, fct_relevel(rincome, "Not applicable"))) +
  geom_point()

?fct_reorder
?fct_relevel

by_age <- gss_cat %>%
  filter(!is.na(age)) %>%
  group_by(age, marital) %>%
  count() %>%
  mutate(prop = n / sum(n))

ggplot(by_age, aes(age, prop, colour = marital)) +
  geom_line(na.rm = TRUE)

ggplot(by_age, aes(age, prop, colour = fct_reorder2(marital, age, prop))) +
  geom_line() +
  labs(colour = "marital")

ggplot(by_age, aes(age, prop, colour = fct_reorder2(marital, age, prop))) +
  geom_line() +
  labs(colour = "marital") # color lined up with legend color 

?fct_reorder2

gss_cat %>%
  mutate(marital = marital %>% fct_infreq() %>% fct_rev()) %>%
  ggplot(aes(marital)) +
    geom_bar()

gss_cat %>%
  mutate(marital = marital %>% fct_infreq() %>% fct_rev())
?fct_infreq
?fct_rev

f <- factor(c("b", "b", "a", "c", "c", "c"))
fct_infreq(f) # from the most frequent to the least frequent...  
```

### 08-16-2017 
```{r}
# 19.1 -- 19.4 
# 19.3.1 skip
# Functions

# intro 
# 19.3 Functions are for humans and computers 

# 19.4 Conditional execution
# vecterized ??? don't understand... 

x <- sqrt(2) ^ 2
x
#> [1] 2
x == 2
#> [1] FALSE
x - 2
#> [1] 4.44e-16

# Instead use dplyr::near() for comparisons, as described in comparisons.

# use swtich(), cut(), instead of many if in conditional statement 

# 19.4.3 Code style 
```

### 08-23-2017 
```{r}
# 19.5 Function arguments 
# 19.5.1 choosing names 
# 19.5.2 checking values 
# It’s good practice to check important preconditions, and throw an error (with stop()), if they are not true: 

# Be careful not to take this too far. There’s a tradeoff between how much time you spend making your function robust, versus how long you spend writing it. 

# A useful compromise is the built-in stopifnot(): it checks that each argument is TRUE, and produces a generic error message if not.

# 19.5.3 Dot-dot-dot 
# Many functions in R take an arbitrary number of inputs: How do these functions work? They rely on a special argument: ... (pronounced dot-dot-dot). 

commas <- function(...) stringr::str_c(..., collapse = ", ")
commas(letters[1:10])

# It’s useful because you can then send those ... on to another function. This is a useful catch-all if your function primarily wraps another function.

rule <- function(..., pad = "-") {
  title <- paste0(...) # paste0(..., collapse) is equivalent to paste(..., sep = "", collapse), slightly more efficiently 
  width <- getOption("width") - nchar(title) - 5
  cat(title, " ", stringr::str_dup(pad, width), "\n", sep = "")
}
rule("Important output")

?paste0
?getOption 

(title <- paste0("Important output")) # paste0(..., collapse) is equivalent to paste(..., sep = "", collapse), slightly more efficiently 
(width <- getOption("width") - nchar(title) - 5)
stringr::str_dup("=", width)
cat(title, " ", stringr::str_dup("=", width), "\n", sep = "")

show_missings <- function(df) {
  n <- sum(is.na(df))
  cat("Missing values: ", n, "\n", sep = "")
  
  invisible(df) # but even without this function df is not getting printed out. 
}

show_missings(mtcars)

show_missings_2 <- function(df) {
  n <- sum(is.na(df))
  paste("Missing values: ", n, "\n", sep = "")
  
  #invisible(df)
}

show_missings_2(mtcars)
x1 <- show_missings_2(mtcars) 
x1
x2 <- show_missings(mtcars) # don't understand why this makes the diference. 
x2

### Envirionment # don't understand 
# Chapter 20 Vectors 
# need purr package 
library(tidyverse)

# Vector basics 
# The chief difference between atomic vectors and lists is that atomic vectors are homogeneous, while lists can be heterogeneous.  

class(letters)
typeof(letters)

?class
?typeof

# Vectors can also contain arbitrary additional metadata in the form of attributes. These attributes are used to create augmented vectors which build on additional behaviour. There are four important types of augmented vector:

# Factors are built on top of integer vectors.
# Dates and date-times are built on top of numeric vectors.
# Data frames and tibbles are built on top of lists.

# so data frames and tibbles can be hetergeneous.  

# important types of atomic vector

# logic
# numeric
typeof(1)
typeof(1L)
1.5L

# difference between double and interger 
# 1) doubles are approximations ??? 
x <- sqrt(2) ^ 2
x
x - 2

sqrt(2) ^ 2 == 2
near(sqrt(2) ^ 2, 2)

# Integers have one special value: NA, while doubles have four: NA, NaN, Inf and -Inf. 

# character
# missing values
NA            # logical
NA_integer_   # integer
NA_real_      # double
NA_character_ # character 
```

#### Using atomic vectors 
```{r}
x <- sample(20, 100, replace = TRUE)
x
y <- x > 10
sum(y)  # how many are greater than 10?
#> [1] 44
mean(y) #
y

library(tidyverse)
is_logical(TRUE)

1:10 + 1:2
1:10 + 1:3
# basic R automatically recycle vectors but this is disabled in tidyverse. 

data.frame(x = 1:4,
      y = 1:2)

tibble(x = 1:4,
       y = 1:2)

tibble(x = 1:4, y = rep(1:2, 2))
tibble(x = 1:4, y = rep(1:2, each = 2))

# all types of vectors can be named, you can name them during creation with c()

# subsetting 
x <- c("one", "two", "three", "four", "five")
x[c(3, 2, 5)]
x[c(1, 1, 5, 5, 5, 2)]
x[c(-1, -3, -5)]'
```

# list
```{r}
# list can contain mix of objects
# and other lists 
x1 <- list(c(1, 2), c(3, 4))
x2 <- list(list(1, 2), list(3, 4))
x3 <- list(1, list(2, list(3)))
x1
x2

# subset list 
# [ extracts a sub-list. The result will always be a list.
# [[ extracts a single component from a list. It removes a level of hierarchy from the list.
# $ is a shorthand for extracting named elements of a list. It works similarly to [[ except that you don’t need to use quotes.

# attributes 
x <- 1:10
x
attr(x, "greeting")
attr(x, "greeting") <- "Hi!"
attr(x, "farewell") <- "Bye!"
attributes(x)

as.Date
methods("as.Date")

# Augmented vectors 
# Atomic vectors and lists are the building blocks for other important vector types like factors and dates. I call these augmented vectors, because they are vectors with additional attributes, including class. 

# four important augmented vectors:

# Factors
# Dates
# Date-times
# Tibbles

x <- factor(c("ab", "cd", "ab"), levels = c("ab", "cd", "ef"))
typeof(x)
attributes(x)

x <- as.Date("1971-01-01")
unclass(x)
typeof(x)
attributes(x)

x <- lubridate::ymd_hm("1970-01-01 01:00")
unclass(x)
typeof(x)
attributes(x)

tb <- tibble::tibble(x = 1:5, y = 5:1)
typeof(tb)
attributes(tb)

# The difference between a tibble and a list is that all the elements of a data frame must be vectors with the same length. 
```

09-06-2017 Iterations 
```{r}
# imperative programming & functional programming 
df <- tibble(
  a = rnorm(10),
  b = rnorm(10),
  c = rnorm(10),
  d = rnorm(10)
)

output <- vector()  ### ??? 
for (i in seq_along(df)) {            # 2. sequence
  output[[i]] <- median(df[[i]])      # 3. body
}
output
typeof(output)

output <- list()  # 1. output
for (i in seq_along(df)) {            # 2. sequence
  output[[i]] <- median(df[[i]])      # 3. body
}
output

y <- vector("double", 0)
seq_along(y) # seq_along deal with vector of length 0 

1:length(y)
```

09-12-2017 
### map 
```{r}
library(tidyverse)
models <- mtcars %>% 
  split(.$cyl) %>% 
  map(function(df) lm(mpg ~ wt, data = df))

models <- mtcars %>% 
  split(.$cyl) %>% 
  map(~lm(mpg ~ wt, data = .))

models %>% 
  map(summary) %>% 
  map_dbl(~.$r.squared)

models %>% 
  map(summary)

models %>% 
  map(summary) %>% 
  map_dbl("r.squared")

x <- list(list(1, 2, 3), list(4, 5, 6), list(7, 8, 9))
x
x %>% map_dbl(2)

x1 <- list(
  c(0.27, 0.37, 0.57, 0.91, 0.20),
  c(0.90, 0.94, 0.66, 0.63, 0.06), 
  c(0.21, 0.18, 0.69, 0.38, 0.77)
)
x2 <- list(
  c(0.50, 0.72, 0.99, 0.38, 0.78), 
  c(0.93, 0.21, 0.65, 0.13, 0.27), 
  c(0.39, 0.01, 0.38, 0.87, 0.34)
)

threshold <- function(x, cutoff = 0.8) x[x > cutoff]
x1 %>% sapply(threshold) %>% str() # diff length 
#> List of 3
#>  $ : num 0.91
#>  $ : num [1:2] 0.9 0.94
#>  $ : num(0)
x2 %>% sapply(threshold) %>% str() # same length
#>  num [1:3] 0.99 0.93 0.87 # why the output here are different... 

# understand different apply!!! 
# One advantage of vapply() over purrr’s map functions is that it can also produce matrices — the map functions only ever produce vectors. 
```

Dealing with failure 
```{r}
safe_log <- safely(log)
str(safe_log(10))
log(10)
str(safe_log("a"))
log("a")
# When the function succeeds, the result element contains the result and the error element is NULL. When the function fails, the result element is NULL and the error element contains an error object 

# safely() is designed to work with map: 
x <- list(1, 10, "a")
y <- x %>% map(safely(log))
str(y)
y <- y %>% transpose() # transpose function 
y
str(y)
?t # Matrix Transpose
?transpose # Transpose a list. 

is_ok <- y$error %>% map_lgl(is_null) # y is result, error is error  
y$error %>% map_lgl(is_null) # 1st two have errors 
is_ok
x
x[!is_ok] # 3rd does not have error 
y$result[is_ok] %>% flatten_dbl()

x <- list(1, 10, "a")
x %>% map_dbl(possibly(log, NA_real_)) # Like safely(), possibly() always succeeds. It’s simpler than safely(), because you give it a default value to return when there is an error.  
#> [1] 0.0 2.3  NA

x <- list(1, -1)
x %>% map(quietly(log)) %>% str()
# quietly() performs a similar role to safely(), but instead of capturing errors, it captures printed output, messages, and warnings: 

# Mapping over multiple arguments 
mu <- list(5, 10, -3)
mu %>% 
  map(rnorm, n = 5) %>% 
  str()

sigma <- list(1, 5, 10)
seq_along(mu) %>% 
  map(~rnorm(5, mu[[.]], sigma[[.]])) %>% 
  str()

seq_along(mu)

# But that obfuscates the intent of the code. Instead we could use map2() which iterates over two vectors in parallel: 
map2(mu, sigma, rnorm, n = 5) %>% str()

# the arguments that vary for each call come before the function; arguments that are the same for every call come after. 

# You could also imagine map3(), map4(), map5(), map6() etc, but that would get tedious quickly. Instead, purrr provides pmap() which takes a list of arguments. You might use that if you wanted to vary the mean, standard deviation, and number of samples: 

n <- list(1, 3, 5)
list(n, mu, sigma)
args1 <- list(n, mu, sigma)
args1 %>%
  pmap(rnorm) %>% 
  str()

args2 <- list(mean = mu, sd = sigma, n = n)
args2 %>% 
  pmap(rnorm) %>% 
  str()

args2 <- list(mean = mu, sd = sigma, n = n)
args2 %>% 
  pmap(rnorm) %>% 
  str()

args2 %>% 
  pmap(rnorm) 

params <- tribble(
  ~mean, ~sd, ~n,
    5,     1,  1,
   10,     5,  3,
   -3,    10,  5
)

params %>% 
  pmap(rnorm)

# Invoking different functions 
f <- c("runif", "rnorm", "rpois")
param <- list(
  list(min = -1, max = 1), 
  list(sd = 5), 
  list(lambda = 10)
)

invoke_map(f, param, n = 5) %>% str()

sim <- tribble(
  ~f,      ~params,
  "runif", list(min = -1, max = 1),
  "rnorm", list(sd = 5),
  "rpois", list(lambda = 10)
)
sim %>% 
  mutate(sim = invoke_map(f, params, n = 10))

# walk 
x <- list(1, "a", 3)

x %>% 
  walk(print)

library(ggplot2)
plots <- mtcars %>% 
  split(.$cyl) %>% 
  map(~ggplot(., aes(mpg, wt)) + geom_point()) # make a plot for each df 
paths <- stringr::str_c(names(plots), ".pdf")
paths
pwalk(list(paths, plots), ggsave, path = tempdir())
pwalk(list(paths, plots), ggsave, path = "~/Desktop/2017_summer/Rclub-r4ds_Ruijuan.Li/R-club-Sep-12/")

list(paths, plots) 
plots # plots is the actural plots 
tempdir()
?tempdir # 

# Other patterns of for loops 
# 21.9.1 Predicate functions 

iris %>% 
  keep(is.factor) %>% 
  str()

iris %>% 
  keep(is.factor) 

iris %>% 
  discard(is.factor) %>% 
  str()

# some() and every() determine if the predicate is true for any or for all of the elements. 
x <- list(1:5, letters, list(10))
x
x %>% 
  some(is_character)

x %>% 
  every(is_vector)

x %>% 
  every(is_character)

set.seed(2)
x <- sample(10) # sample 100 numbers from 1-100 with no replacement 
x

x %>% 
  detect(~ . > 5)

x %>% 
  detect_index(~ . > 5) 

# head_while() and tail_while() take elements from the start or end of a vector while a predicate is true: 
x %>% 
  head_while(~ . > 1)

x %>% 
  tail_while(~ . > 5)
x

# Reduce and accumulate 
dfs <- list(
  age = tibble(name = "John", age = 30),
  sex = tibble(name = c("John", "Mary"), sex = c("M", "F")),
  trt = tibble(name = "Mary", treatment = "A")
)

dfs

dfs %>% reduce(full_join)

vs <- list(
  c(1, 3, 5, 6, 10),
  c(1, 2, 3, 7, 8, 10),
  c(1, 2, 3, 4, 8, 9, 10)
)

vs %>% reduce(intersect) # this is very important 

x <- sample(10)
x
x %>% accumulate(`+`)
```

### 09-20-2017 
```{r}
# ? query set in model prediciton... 
library(tidyverse)

library(modelr)
options(na.action = na.warn)

# 23.2 A simple model 
ggplot(sim1, aes(x, y)) + 
  geom_point()

sim1 %>% head()

models <- tibble(
  a1 = runif(250, -20, 40),
  a2 = runif(250, -5, 5)
)

ggplot(sim1, aes(x, y)) + 
  geom_abline(aes(intercept = a1, slope = a2), data = models, alpha = 1/4) +
  geom_point() 

model1 <- function(a, data) {
  a[1] + data$x * a[2]
}
model1(c(7, 1.5), sim1) ## this gives the y value for a1 = 7 and a2 = 1.5 

measure_distance <- function(mod, data) {
  diff <- data$y - model1(mod, data)
  sqrt(mean(diff ^ 2))
} ## this gives the r square 
measure_distance(c(7, 1.5), sim1)

sim1_dist <- function(a1, a2) {
  measure_distance(c(a1, a2), sim1)
}

models <- models %>% 
  mutate(dist = purrr::map2_dbl(a1, a2, sim1_dist))
models %>% head()

ggplot(sim1, aes(x, y)) + 
  geom_point(size = 2, colour = "grey30") + 
  geom_abline(
    aes(intercept = a1, slope = a2, colour = -dist), 
    data = filter(models, rank(dist) <= 10)
  )

ggplot(models, aes(a1, a2)) +
  geom_point(data = filter(models, rank(dist) <= 10), size = 4, colour = "red") +
  geom_point(aes(colour = -dist))

grid <- expand.grid(
  a1 = seq(-5, 20, length = 25),
  a2 = seq(1, 3, length = 25)
  ) %>% 
  mutate(dist = purrr::map2_dbl(a1, a2, sim1_dist))

grid %>% 
  ggplot(aes(a1, a2)) +
  geom_point(data = filter(grid, rank(dist) <= 10), size = 4, colour = "red") +
  geom_point(aes(colour = -dist))

ggplot(sim1, aes(x, y)) + 
  geom_point(size = 2, colour = "grey30") + 
  geom_abline(
    aes(intercept = a1, slope = a2, colour = -dist), 
    data = filter(grid, rank(dist) <= 10)
  )

best <- optim(c(0, 0), measure_distance, data = sim1)
best$par

ggplot(sim1, aes(x, y)) + 
  geom_point(size = 2, colour = "grey30") + 
  geom_abline(intercept = best$par[1], slope = best$par[2])

sim1_mod <- lm(y ~ x, data = sim1)
coef(sim1_mod)
```

### 09-27-2017 
```{r}
# visualizing models 
## predictions 
grid <- sim1 %>% 
  data_grid(x)

class(grid)
grid 
sim1 %>% dim() 
?data_grid 

grid <- grid %>% 
  add_predictions(sim1_mod) 
grid
sim1_mod
?add_predictions # add predictions to a data frame 

ggplot(sim1, aes(x)) +
  geom_point(aes(y = y)) +
  geom_line(aes(y = pred), data = grid, colour = "red", size = 1)

# 23.3.2 Residuals 
sim1 <- sim1 %>% 
  add_residuals(sim1_mod)
sim1

ggplot(sim1, aes(resid)) + 
  geom_freqpoly(binwidth = 0.5)
# Note that the average of the residual will always be 0. 

ggplot(sim1, aes(x, resid)) + 
  geom_ref_line(h = 0) + # adding a reference line 
  geom_point()

# Formulas and model families
df <- tribble(
  ~y, ~x1, ~x2,
  4, 2, 5,
  5, 1, 6
)
df

model_matrix(df, y ~ x1) # do not understand 

# 23.4.1 Categorical variables
df <- tribble(
  ~ sex, ~ response,
  "male", 1,
  "female", 2,
  "male", 1
)
df
model_matrix(df, response ~ sex) # model automatically convert categorical value factor into values... 

ggplot(sim2) + 
  geom_point(aes(x, y))

mod2 <- lm(y ~ x, data = sim2)

grid <- sim2 %>% 
  data_grid(x) %>% 
  add_predictions(mod2)
grid 

ggplot(sim2, aes(x)) + 
  geom_point(aes(y = y)) +
  geom_point(data = grid, aes(y = pred), colour = "red", size = 4)

tibble(x = "e") %>% 
  add_predictions(mod2)

# 23.4.2 Interactions (continuous and categorical)
ggplot(sim3, aes(x1, y)) + 
  geom_point(aes(colour = x2))

mod1 <- lm(y ~ x1 + x2, data = sim3)
mod2 <- lm(y ~ x1 * x2, data = sim3)
class(sim3$x1) # integer 
class(sim3$x2) # factor 

grid <- sim3 %>% 
  data_grid(x1, x2) %>% 
  gather_predictions(mod1, mod2)

grid

ggplot(sim3, aes(x1, y, colour = x2)) + 
  geom_point() + 
  geom_line(data = grid, aes(y = pred)) + 
  facet_wrap(~ model)

sim3 <- sim3 %>% 
  gather_residuals(mod1, mod2)
sim3


ggplot(sim3, aes(x1, resid, colour = x2)) + 
  geom_point() + 
  facet_grid(model ~ x2)

?gather_residuals # add residual to data frame 

# 23.4.3 Interactions (two continuous)
mod1 <- lm(y ~ x1 + x2, data = sim4)
mod2 <- lm(y ~ x1 * x2, data = sim4)

grid <- sim4 %>% 
  data_grid(
    x1 = seq_range(x1, 5), # regularly spaced grid of five values between the minimum and maximum numbers 
    x2 = seq_range(x2, 5) 
  ) %>% 
  gather_predictions(mod1, mod2)
grid

seq_range(c(0.0123, 0.923423), n = 5)
seq_range(c(0.0123, 0.923423), n = 5, pretty = TRUE)

x1 <- rcauchy(100)
seq_range(x1, n = 5)
seq_range(x1, n = 5, trim = 0.10)
seq_range(x1, n = 5, trim = 0.25)
seq_range(x1, n = 5, trim = 0.50)

x2 <- c(0, 1)
seq_range(x2, n = 5)
seq_range(x2, n = 5, expand = 0.10)
seq_range(x2, n = 5, expand = 0.25)
seq_range(x2, n = 5, expand = 0.50)

ggplot(grid, aes(x1, x2)) + 
  geom_tile(aes(fill = pred)) + 
  facet_wrap(~ model)

grid$pred

ggplot(grid, aes(x1, pred, colour = x2, group = x2)) + 
  geom_line() +
  facet_wrap(~ model)
ggplot(grid, aes(x2, pred, colour = x1, group = x1)) + 
  geom_line() +
  facet_wrap(~ model)

grid

# 23.4.4 Transformations 
```

### 10-27-2017 
```{r}
# model buiding
library(tidyverse)
library(modelr)
options(na.action=na.warn)

library(nycflights13)
library(lubridate)

ggplot(diamonds, aes(cut, price)) + geom_boxplot()
ggplot(diamonds, aes(color, price)) + geom_boxplot()
ggplot(diamonds, aes(clarity, price)) + geom_boxplot()

ggplot(diamonds, aes(carat, price)) + 
  geom_hex(bins = 50)

diamonds2 <- diamonds %>% 
  filter(carat <= 2.5) %>% 
  mutate(lprice = log2(price), lcarat = log2(carat))

ggplot(diamonds2, aes(lcarat, lprice)) + 
  geom_hex(bins = 50)

mod_diamond <- lm(lprice ~ lcarat, data = diamonds2)

grid <- diamonds2 %>% 
  data_grid(carat = seq_range(carat, 20)) %>% # simulate 20 carat data based on the current range 
  mutate(lcarat = log2(carat)) %>% # log transform 
  add_predictions(mod_diamond, "lprice") %>% # add predictions from model 
  mutate(price = 2 ^ lprice) # transform prediction back to raw data 

# adding prediction line to the raw data 
ggplot(diamonds2, aes(carat, price)) + 
  geom_hex(bins = 50) + 
  geom_line(data = grid, colour = "red", size = 1)

# add residule 
diamonds2 <- diamonds2 %>% 
  add_residuals(mod_diamond, "lresid")

ggplot(diamonds2, aes(lcarat, lresid)) + 
  geom_hex(bins = 50)

mod_diamond2 <- lm(lprice ~ lcarat + color + cut + clarity, data = diamonds2)

grid <- diamonds2 %>% 
  data_grid(cut, .model = mod_diamond2) %>% 
  add_predictions(mod_diamond2)
grid %>% head()
mod_diamond2

?data_grid
diamonds2 <- diamonds2 %>% 
  add_residuals(mod_diamond2, "lresid2")

ggplot(diamonds2, aes(lcarat, lresid2)) + 
  geom_hex(bins = 50)

diamonds2 %>% 
  filter(abs(lresid2) > 1) %>% 
  add_predictions(mod_diamond2) %>% 
  mutate(pred = round(2 ^ pred)) %>% 
  select(price, pred, carat:table, x:z) %>% 
  #colnames()
  arrange(price)

# What affects the number of daily flights 
daily <- flights %>% 
  mutate(date = make_date(year, month, day)) %>% # way of making date column 
  group_by(date) %>% 
  summarise(n = n())
daily

ggplot(daily, aes(date, n)) + 
  geom_line()

daily <- daily %>% 
  mutate(wday = wday(date, label = TRUE)) # label the 
ggplot(daily, aes(wday, n)) + 
  geom_boxplot()

daily
?wday

mod <- lm(n ~ wday, data = daily)

grid <- daily %>% 
  data_grid(wday) %>% 
  add_predictions(mod, "n")

ggplot(daily, aes(wday, n)) + 
  geom_boxplot() +
  geom_point(data = grid, colour = "red", size = 4)

daily <- daily %>% 
  add_residuals(mod)
daily %>% 
  ggplot(aes(date, resid)) + 
  geom_ref_line(h = 0) + 
  geom_line()

ggplot(daily, aes(date, resid, colour = wday)) + 
  geom_ref_line(h = 0) + 
  geom_line()

daily %>% 
  filter(resid < -100)

daily %>% 
  ggplot(aes(date, resid)) + 
  geom_ref_line(h = 0) + 
  geom_line(colour = "grey50") + 
  geom_smooth(se = FALSE, span = 0.20)
?geom_smooth # 

daily %>% 
  filter(wday == "Sat") %>% 
  ggplot(aes(date, n)) + 
    geom_point() + 
    geom_line()  +
    scale_x_date(NULL, date_breaks = "1 month", date_labels = "%b") # new code that I have never used before... 

term <- function(date) {
  cut(date, 
    breaks = ymd(20130101, 20130605, 20130825, 20140101),
    labels = c("spring", "summer", "fall") 
  )
}

term
daily <- daily %>% 
  mutate(term = term(date)) 
daily

daily %>% 
  filter(wday == "Sat") %>% 
  ggplot(aes(date, n, colour = term)) +
  geom_point(alpha = 1/3) + 
  geom_line() +
  scale_x_date(NULL, date_breaks = "1 month", date_labels = "%b")

daily %>% 
  ggplot(aes(wday, n, colour = term)) +
    geom_boxplot()

mod1 <- lm(n ~ wday, data = daily)
mod2 <- lm(n ~ wday * term, data = daily)

daily %>% 
  gather_residuals(without_term = mod1, with_term = mod2) %>% 
  ggplot(aes(date, resid, colour = model)) +
    geom_line(alpha = 0.75)

grid <- daily %>% 
  data_grid(wday, term) %>% 
  add_predictions(mod2, "n")

ggplot(daily, aes(wday, n)) +
  geom_boxplot() + 
  geom_point(data = grid, colour = "red") + 
  facet_wrap(~ term)

mod3 <- MASS::rlm(n ~ wday * term, data = daily) # rlm is robust to the effect of outliers.

daily %>% 
  add_residuals(mod3, "resid") %>% 
  ggplot(aes(date, resid)) + 
  geom_hline(yintercept = 0, size = 2, colour = "white") + 
  geom_line() 

# I do not see how this improve the model 

library(splines)
mod <- MASS::rlm(n ~ wday * ns(date, 5), data = daily) 

daily %>% 
  data_grid(wday, date = seq_range(date, n = 13)) %>% 
  add_predictions(mod) %>% 
  ggplot(aes(date, pred, colour = wday)) + 
    geom_line() +
    geom_point()
# do not quite understand the above portion. 
```





















